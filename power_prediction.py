# -*- coding: utf-8 -*-
"""Power Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U-0ergjMd7BPTNEtw1IB80AYty5gmO8u
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline

train_df = pd.read_csv('/content/drive/MyDrive/HackerEarth Power Generated Challenge /train.csv')
test_df = pd.read_csv('/content/drive/MyDrive/HackerEarth Power Generated Challenge /test.csv')

train_df.head()

test_df

train_df.describe()

#Replacing low, medium, extremely low in cloud level column with their one hot encoded values

train_df['cloud_level'] = train_df['cloud_level'].replace({'Low' : 0 , 'Medium' : 1, 'Extremely Low' : -1})

#Doing the same as above for test set

test_df['cloud_level'] = test_df['cloud_level'].replace({'Low' : 0 , 'Medium' : 1, 'Extremely Low' : -1})

#Replacing the various text described values in the column turbine_status with their one hot encode values
onehotencods = {}
for i in range(len(train_df['turbine_status'].unique())):
  onehotencods[train_df['turbine_status'].unique()[i]] = i
  train_df['turbine_status'].replace({train_df['turbine_status'].unique()[i] : i}, inplace = True)

onehotencods

#Applying these one hot encoded numbers in test dataset 
test_df['turbine_status'].replace(onehotencods, inplace = True)

print(test_df['turbine_status'].value_counts())

#Replace the nan values in the train dataset by corresponding median values of the column

for i in range(len(train_df.describe().columns)):
  train_df.iloc[:,i+2].replace(np.NAN,train_df.iloc[:,i+2].median(),inplace = True)

train_df.describe()

#Doing the same for the test set 
for i in range(len(test_df.describe().columns)):
  test_df.iloc[:,i+2].replace(np.NAN,test_df.iloc[:,i+2].median(),inplace = True)

test_df.describe()

#Shuffling the indices 
np.random.seed(10)
n_dev = 3200 #Data for dev set
shuffled_indices = np.random.permutation(train_df.shape[0])

#Load the train data into numpy arrays
x = np.array(train_df.loc[:,'wind_speed(m/s)':'windmill_height(m)'])
y = np.array(train_df['windmill_generated_power(kW/h)'])

#Make train and dev sets
x_train = x[shuffled_indices[n_dev:]]
y_train = y[shuffled_indices[n_dev:]]

x_dev = x[shuffled_indices[:n_dev]]
y_dev = y[shuffled_indices[:n_dev]]

x_train.shape

#Plot the graph between various features and Wind power values 

plt.style.use('seaborn')
plt.xlabel('Wind_speed(m/s)')
plt.ylabel('Windmill Generated Power')
plt.scatter(train_df['wind_speed(m/s)'],train_df['windmill_generated_power(kW/h)'], s = 4)

plt.style.use('seaborn')
plt.xlabel('')
plt.ylabel('Windmill Generated Power')
plt.scatter(train_df['atmospheric_temperature(Â°C)'],train_df['windmill_generated_power(kW/h)'], s = 4)

#Reshape y_train
y_train = y_train.reshape(-1,1)
y_dev = y_dev.reshape(-1,1)

#Load the test data into numpy arrays
x_test = np.array(test_df.loc[:,'wind_speed(m/s)':'windmill_height(m)'])

#Normalizing the data now
x_train = (x_train - x_train.mean(axis = 0))/x_train.std(axis = 0)
x_dev = (x_dev - x_dev.mean(axis = 0))/ x_dev.std(axis = 0)
x_test = (x_test - x_test.mean(axis = 0))/x_test.std(axis = 0)

import torch
import torch.nn as nn 
from torch.utils.data import DataLoader, Dataset

#Making the input data a Pytorch Dataset
class PowerDataset(Dataset):
  def __init__(self,x,y):
    x = x.astype(np.float32)
    y = y.astype(np.float32)
    #Make the input data a torch tensor
    self.x = torch.from_numpy(x)
    self.y = torch.from_numpy(y)

  def __getitem__(self,index):
    return self.x[index],self.y[index]

  def __len__(self):
    return self.x.shape[0]

train_dataset = PowerDataset(x_train, y_train)
dev_dataset = PowerDataset(x_dev , y_dev)

train_dataset[0]

#Make the model now
class PowerPredictor(nn.Module):
  def __init__(self,input_features,num_outputs,neuronslist):
    super().__init__()
    self.input_features = input_features
    self.num_outputs = num_outputs
    self.neuronslist = neuronslist
    '''Here,
    input_features : Number of different features in dataset
    num_outputs : Number of outputs
    neuronslist : List of number of hidden units per layer 
                  (Since there are three layers so there will be three elements in this list'''

            
    self.linear1 = nn.Linear(self.input_features,self.neuronslist[0])
    self.act1 = nn.Softplus()

    self.linear3 = nn.Linear(self.neuronslist[0], self.neuronslist[1])
    self.act3 = nn.Softplus()

    self.linear6 = nn.Linear(self.neuronslist[1], self.num_outputs)
    self.act6 = nn.Softplus()

  def forward(self,x):
    out = self.act1(self.linear1(x))
    #out = self.act2(self.linear2(out))
    out = self.act3(self.linear3(out))
    #out = self.act4(self.linear4(out))
    #out = self.act5(self.linear5(out))
    out = self.act6(self.linear6(out))
    return out

model = PowerPredictor(input_features=19,num_outputs=1,neuronslist=[16,8])
model.to('cuda')

#model.load_state_dict(torch.load('/content/drive/MyDrive/HackerEarth Power Generated Challenge /PowerPredictionWeights.pt'))

#Making the data loaders now
batch_size = 256
train_loader = DataLoader(train_dataset,batch_size)
dev_loader = DataLoader(dev_dataset, batch_size)

#Define the loss function
loss_fn = nn.MSELoss() #The loss defined for the problem question is 100 multiplied by the mse loss that it will be incorporated later

opt = torch.optim.SGD(model.parameters(), lr = (1e-3))

model.train()
num_epochs = 500
iters = []
loss_per_epoch = []
for epochs in range(1,num_epochs+1):
  loss_epoch = 0.0
  for inputs, outputs in train_loader:
    inputs , outputs = inputs.to('cuda'), outputs.to('cuda')
    preds = model(inputs)
    loss = loss_fn(preds.view(-1),outputs.view(-1))
    loss.backward()
    opt.step()
    opt.zero_grad()
    loss_epoch += loss
  loss_per_epoch.append(loss_epoch)
  iters.append(epochs)
  if epochs % 5 == 0 :
    print("[{}/{}] Loss : {}".format(epochs,num_epochs,loss_epoch))

#Checking the loss on dev set
model.eval()
loss_dev = 0.0
for inputs_dev , outputs_dev in dev_loader:
  inputs_dev , outputs_dev  = inputs_dev.to('cuda'), outputs_dev.to('cuda')
  preds_dev = model(inputs)
  loss = loss_fn(preds_dev.view(-1),outputs.view(-1))
  loss_dev += loss
print("Loss on dev set : {}".format(loss_dev))

#Plot the graph of loss with iterations
plt.title('Loss with iterations')
plt.style.use('seaborn')
plt.xlabel('Iterations')
plt.ylabel('Loss')
plt.plot(iters,loss_per_epoch)

#Save the model
PATH = '/content/drive/MyDrive/HackerEarth Power Generated Challenge /PowerPredictionWeightsOneSoftplus.pt'
torch.save(model.state_dict(),PATH)

#Preparing the test data
x_test = x_test.astype(np.float32)
x_test = torch.from_numpy(x_test)
x_test = x_test.to('cuda')

#Evaluate the model on test dataset
model.eval()
preds_test = model(x_test)

preds_test.shape

preds_test_df = test_df.loc[:,'tracking_id':'datetime']

preds_test_df['windmill_generated_power(kW/h)'] = preds_test.cpu().detach().numpy()

preds_test_df.describe()

train_df.describe()

preds_test_df.to_csv('preds_test.csv', index= False)

preds_test_df

test_df

